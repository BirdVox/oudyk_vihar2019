{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import librosa.feature\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import glob\n",
    "\n",
    "\n",
    "# t-2 Voice Activity Detection function\n",
    "def detect_activity(y, sr,\n",
    "        n_mels=128, fmin=1000, fmax=11025, \n",
    "        hop_length=512, gain=0.8, bias=10, power=0.25, pcen_time_constant=0.06, eps=1e-06,\n",
    "        medfilt_time_constant=None, normalized=True,\n",
    "        peak_threshold=0.45, activity_threshold=0.2):\n",
    "    \n",
    "    # 1. Compute mel-frequency spectrogram\n",
    "    melspec = librosa.feature.melspectrogram(\n",
    "        y, sr=sr, fmin=fmin, fmax=fmax, hop_length=hop_length,\n",
    "        n_mels=n_mels)\n",
    "    \n",
    "    # 2. Compute per-channel energy normalization (PCEN-SNR)\n",
    "    pcen = librosa.core.pcen(melspec, sr=sr, gain=gain, bias=bias,\n",
    "        power=power, hop_length=hop_length,\n",
    "        time_constant=pcen_time_constant, eps=eps)\n",
    "    \n",
    "    # 3. compute PCEN-SNR detection function\n",
    "    pcen_snr = np.max(pcen,axis=0) - np.min(pcen,axis=0)\n",
    "    pcen_snr = librosa.power_to_db(pcen_snr / np.median(pcen_snr))\n",
    "    if normalized:\n",
    "        pcen_snr = pcen_snr / np.max(pcen_snr)\n",
    "        \n",
    "    # 4. Apply median filtering.\n",
    "    if medfilt_time_constant is not None:\n",
    "        medfilt_hops = medfilt_time_constant * sr / hop_length\n",
    "        kernel_size = max(1, 1 + 2 * round(medfilt_hops - 0.5))\n",
    "        pcen_snr = scipy.signal.medfilt(pcen_snr, kernel_size=kernel_size)\n",
    "    \n",
    "    # 5. Extract active segments.\n",
    "    activity, start, end = threshold_activity(\n",
    "        pcen_snr, peak_threshold, activity_threshold)\n",
    "    \n",
    "    # 6. Convert indices to seconds.\n",
    "    start_times = np.round(np.array(start) * hop_length / sr, 3)\n",
    "    end_times = np.round(np.array(end) * hop_length / sr, 3)\n",
    "    \n",
    "    return start_times, end_times, pcen\n",
    "\n",
    "\n",
    "def threshold_activity(x, Tp, Ta):\n",
    "    locs = scipy.signal.find_peaks(x,height = Tp)[0]\n",
    "    y = (x > Ta) * 1\n",
    "    act = np.diff(y)\n",
    "    u = np.where(act == 1)[0]\n",
    "    d = np.where(act == -1)[0]\n",
    "    signal_length = len(x)\n",
    "    \n",
    "    if d[0] < u[0]:\n",
    "        u = np.insert(u, 0, 0)\n",
    "        \n",
    "    if d[-1] < u[-1]:\n",
    "        d = np.append(d, signal_length-1)\n",
    "        \n",
    "    starts = []\n",
    "    ends = []\n",
    "    \n",
    "    activity = np.zeros(signal_length,)\n",
    "    \n",
    "    for candidate_up, candidate_down in zip(u, d):\n",
    "        candidate_segment = range(candidate_up, candidate_down)\n",
    "        peaks_in_segment = [x in candidate_segment for x in locs]\n",
    "        is_valid_candidate = np.any(peaks_in_segment)\n",
    "        if is_valid_candidate:\n",
    "            starts.append(candidate_up)\n",
    "            ends.append(candidate_down)\n",
    "            activity[candidate_segment] = 1.0\n",
    "            \n",
    "    starts = np.array(starts)\n",
    "    ends = np.array(ends)\n",
    "    \n",
    "    return activity, starts, ends\n",
    "\n",
    "\n",
    "def get_events_time(rdata):\n",
    "\n",
    "    rdata_nz = np.nonzero(rdata)[0][-1]\n",
    "    fdata = rdata[0:rdata_nz]\n",
    "        \n",
    "    S = librosa.feature.melspectrogram(fdata,n_mels = 256,n_fft=2048, hop_length = 512)\n",
    "    pcen = librosa.core.pcen(S, sr=44100,\n",
    "    gain=0.8, bias=10, power=0.25, time_constant=0.06, eps=1e-06)\n",
    "    \n",
    "    pcen_snr = np.max(pcen,axis=0) - np.min(pcen,axis=0)\n",
    "    pcen_snr = librosa.power_to_db(pcen_snr / np.median(pcen_snr))\n",
    "    pcen_snr = pcen_snr / np.max(pcen_snr)\n",
    "    median_pcen_snr = scipy.signal.medfilt(pcen_snr, kernel_size=3)\n",
    "    \n",
    "    activity, start, end = threshold_activity(median_pcen_snr,0.45,0.15)\n",
    "    activity_count = len(start)\n",
    "    \n",
    "    return start, end, pcen\n",
    "\n",
    "\n",
    "def get_coef(start, end, pcen):\n",
    "\n",
    "    a_all = []\n",
    "    b_all = []\n",
    "    max_list = []\n",
    "    min_list = []\n",
    "    poly_coef = []\n",
    "        \n",
    "    for s,e in zip(start,end):   \n",
    "        bins = np.argmax(pcen[:,s:e],0)\n",
    "        bins_filt = bins[(bins < np.mean(bins) + 2*np.std(bins)) & (bins > np.mean(bins) - 2*np.std(bins)) & (bins<200)& (bins>5)]\n",
    "\n",
    "        if len(bins_filt) > 2:\n",
    "            x = np.array(range(0,len(bins_filt)))\n",
    "            x = x - np.mean(x)\n",
    "            z = np.polyfit(x, bins_filt, 2)\n",
    "\n",
    "            p = np.poly1d(z)\n",
    "            a = z[0]\n",
    "            b = z[1]\n",
    "            poly_coef = np.append(poly_coef, z[0:2])\n",
    "    \n",
    "            # Store needed variables - coefficients, max and min\n",
    "            a_all = np.append(a_all,a)\n",
    "            b_all = np.append(b_all,b)\n",
    "            xp = np.linspace(x.min(), x.max(), len(bins_filt))\n",
    "            max_list = np.append(max_list,x.max())\n",
    "            min_list = np.append(min_list,x.min())\n",
    "\n",
    "    return a_all, b_all, max_list, min_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pitch_contour(a_sti_all,b_sti_all,max_sti_list,min_sti_list):\n",
    "    sti_states = []\n",
    "    for a,b,amax,amin in zip(a_sti_all,b_sti_all,max_sti_list,min_sti_list):\n",
    "        if a > 0.01:\n",
    "            if -b / (2*a) <= amin:\n",
    "                seq = 'uuu'\n",
    "            elif 0 >= -b / (2*a) > amin :\n",
    "                seq = 'duu'\n",
    "            elif amax > -b / (2*a) > 0:\n",
    "                seq = 'ddu'\n",
    "            else:\n",
    "                seq = 'ddd'\n",
    "            \n",
    "        elif a < -0.01:\n",
    "            if -b / (2*a) <= amin:\n",
    "                seq = 'ddd'\n",
    "            elif 0 >= -b / (2*a) > amin :\n",
    "                seq = 'udd'\n",
    "            elif amax > -b / (2*a) > 0:\n",
    "                seq = 'uud'\n",
    "            else:\n",
    "                seq = 'uuu'\n",
    "            \n",
    "        else:\n",
    "            if b > 0.1:\n",
    "                seq = 'uuu'\n",
    "            elif b < -0.1:\n",
    "                seq = 'ddd'\n",
    "            else:\n",
    "                seq = 'fff'\n",
    "                \n",
    "        sti_states.append(seq)  \n",
    "    return sti_states\n",
    "\n",
    "def pitch_countour_numerical(state_str):\n",
    "    state_list = ['uuu', 'duu', 'ddu', 'ddd', 'udd', 'uud', 'uuu', 'fff']\n",
    "    state_int = [i for i,s in enumerate(state_list) if state in s]\n",
    "\n",
    "    print(state_int)\n",
    "        \n",
    "    return states_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uud\n",
      "[7]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'states_int' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-08b1d9be69c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_countour_numerical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-aa072e6625e2>\u001b[0m in \u001b[0;36mpitch_countour_numerical\u001b[0;34m(state_str)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstates_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'states_int' is not defined"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "print(ex[n])\n",
    "print(pitch_countour_numerical(ex[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uud', 'uud', 'uud', 'uud', 'fff']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uud (array([], dtype=int64),)\n",
      "uud (array([], dtype=int64),)\n",
      "uud (array([], dtype=int64),)\n",
      "uud (array([], dtype=int64),)\n",
      "fff (array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i, state in enumerate(ex):\n",
    "    state_numerical = pitch_countour_numerical(state)\n",
    "    print(state, state_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching = \n",
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tqdm\n",
    "import h5py\n",
    "\n",
    "# select participants and spcies\n",
    "participant_paths = np.array(glob.glob(\"imitations_participant*.mat\"))\n",
    "participant_paths.sort()\n",
    "participant_paths = participant_paths[([0, 4, 5, 8, 10, 11])]\n",
    "\n",
    "n_participants = len(participant_paths)\n",
    "n_imitations = 100\n",
    "imitation_matrix = []\n",
    "stimulus_matrix = []\n",
    "species_matrix = []\n",
    "\n",
    "species_subset = np.array([4, 5, 8, 10])\n",
    "imitation_subset = np.zeros(n_imitations)\n",
    "for n in species_subset:\n",
    "    imitation_subset[range(n*10-10, n*10)] = 1\n",
    "imitation_subset = np.array(np.where(imitation_subset)).tolist()[0]\n",
    "\n",
    "for participant_path in tqdm.tqdm(participant_paths):\n",
    "    imitation_list = []\n",
    "    stimulus_list = []\n",
    "    species_list = []\n",
    "    \n",
    "    with h5py.File(participant_path) as h5_file:\n",
    "        for i in imitation_subset:\n",
    "            imitation_waveform = h5_file['#refs#'][\n",
    "                h5_file[\"imitations\"][\"imitationAudio\"][i][0]][0]\n",
    "            stimulus_waveform = h5_file['#refs#'][\n",
    "                h5_file[\"imitations\"][\"stimulusAudio\"][i][0]][0]\n",
    "            species = int(h5_file['#refs#'][\n",
    "                h5_file[\"imitations\"][\"species\"][i][0]][0][0])\n",
    "            \n",
    "            imitation_list.append(imitation_waveform)\n",
    "            stimulus_list.append(stimulus_waveform)\n",
    "            species_list.append(species)\n",
    "            \n",
    "        imitation_matrix.append(imitation_list)\n",
    "        stimulus_matrix.append(stimulus_list)\n",
    "        species_matrix.append(species_list)\n",
    "        \n",
    "imitation_matrix = np.array(imitation_matrix)\n",
    "stimulus_matrix = np.array(stimulus_matrix)\n",
    "stimulus_matrix = stimulus_matrix[0,:]\n",
    "species_matrix = np.array(species_matrix)\n",
    "\n",
    "n_species = int(stimulus_matrix.shape[0] / 10)\n",
    "n_imitations = int(imitation_matrix.shape[0] * imitation_matrix.shape[1])\n",
    "n_participants = imitation_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_stimuli = stimulus_matrix\n",
    "need_data = imitation_matrix\n",
    "\n",
    "states_sti_list = []\n",
    "states_im_matrix = []\n",
    "    \n",
    "    \n",
    "for i in np.arange(n_species * 10):   \n",
    "    rdata_sti = need_stimuli[i]\n",
    "    rdata_sti = rdata_sti[2:-1]\n",
    "    start_sti, end_sti, pcen_sti = get_events_time(rdata_sti)\n",
    "    a_sti, b_sti, max_list_sti, min_list_sti = get_coef(start_sti, end_sti, pcen_sti)\n",
    "    states_sti = pitch_contour(a_sti, b_sti, max_list_sti, min_list_sti)\n",
    "    states_sti_list.append(states_sti)\n",
    "    \n",
    "    states_im_list = []\n",
    "    for j in np.arange(n_participants):\n",
    "        rdata = need_data[j, i]\n",
    "        rdata = rdata[2:-1]\n",
    "        start, end, pcen = get_events_time(rdata)\n",
    "        a,b,max_list,min_list = get_coef(start, end, pcen)\n",
    "        states_im = pitch_contour(a,b,max_list,min_list)\n",
    "        states_im_list.append(states_im)\n",
    "    states_im_matrix.append(states_im_list)\n",
    "        \n",
    "states_sti_list = np.array(states_sti_list)\n",
    "states_im_matrix = np.array(states_im_matrix).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uud', 'uud', 'uud', 'uud', 'fff']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uuu', 'uud', 'uud']\n",
      "['uuu', 'ddd', 'ddd']\n",
      "['ddd', 'fff', 'fff', 'fff', 'fff', 'fff', 'fff']\n",
      "['udd', 'uud', 'uuu', 'ddd', 'ddd', 'uud', 'uud', 'uuu', 'uud', 'fff']\n",
      "['fff', 'uuu', 'ddd', 'fff', 'uud', 'uuu']\n",
      "['fff', 'uud', 'udd', 'ddd', 'uuu', 'uuu', 'duu', 'ddu']\n",
      "['uud', 'uud', 'uud', 'uud', 'fff']\n",
      "['uuu', 'fff', 'uud', 'fff', 'fff']\n",
      "['uuu', 'ddd']\n",
      "['fff', 'udd']\n",
      "['uuu', 'ddd', 'fff', 'uud', 'uud']\n",
      "['uud', 'uud', 'uud', 'ddd', 'uuu', 'ddd', 'udd', 'uud', 'ddd', 'udd']\n",
      "['fff', 'uuu', 'uud', 'fff']\n",
      "['duu', 'udd', 'uud', 'ddd', 'uud', 'fff', 'ddd']\n",
      "['udd']\n",
      "['fff', 'uud']\n",
      "['duu', 'uuu', 'ddd', 'fff', 'udd', 'ddu']\n",
      "['uuu', 'udd', 'uuu', 'uud', 'ddd', 'ddu', 'uud']\n",
      "['uud', 'uud', 'ddu', 'uud', 'uud']\n",
      "['uud', 'uud', 'fff', 'fff', 'fff']\n",
      "['udd', 'uud', 'uuu', 'udd', 'uud', 'uud', 'ddd', 'uud', 'udd', 'duu', 'udd']\n",
      "['udd', 'udd', 'udd', 'ddd', 'ddd', 'uud']\n",
      "['uuu', 'duu', 'uuu', 'uuu', 'duu', 'uuu', 'uuu', 'uuu', 'uuu', 'uuu', 'uuu', 'uuu', 'uuu', 'uuu', 'uuu', 'duu', 'duu', 'uuu']\n",
      "['uuu', 'uuu', 'uuu', 'uuu', 'uuu', 'duu', 'uuu', 'uuu', 'uuu', 'uuu']\n",
      "['uuu', 'udd', 'uuu', 'udd', 'uuu', 'ddd', 'uuu', 'udd', 'uuu', 'ddd', 'uuu', 'uud', 'uuu', 'uuu', 'ddu', 'uuu']\n",
      "['udd', 'duu', 'duu', 'duu', 'ddd', 'uuu', 'duu', 'uuu']\n",
      "['ddd', 'ddd', 'ddd', 'ddd', 'uud', 'ddd', 'udd', 'ddd', 'ddd', 'ddd', 'ddd', 'ddd']\n",
      "['uuu', 'ddd', 'ddd', 'ddd', 'ddd', 'udd', 'ddd', 'udd', 'ddd']\n",
      "['ddu', 'ddu', 'ddd', 'udd', 'duu', 'ddu', 'uud', 'uud', 'uud', 'uud', 'uud', 'uud', 'ddu', 'ddu']\n",
      "['udd', 'ddd', 'duu', 'uuu', 'duu', 'uuu', 'uuu', 'uuu']\n",
      "['duu', 'udd', 'duu', 'udd', 'duu', 'duu', 'duu', 'duu', 'duu']\n",
      "['uuu', 'duu', 'uuu', 'uuu', 'uuu', 'duu']\n",
      "['udd', 'ddd', 'ddd', 'udd', 'udd', 'udd', 'uud', 'uud', 'ddd', 'ddd', 'udd', 'uud', 'uud']\n",
      "['uuu', 'uuu', 'udd', 'ddd', 'ddd', 'uud', 'uud', 'ddd', 'fff']\n",
      "['uud', 'uud', 'duu', 'uud', 'uud', 'uud', 'uuu', 'uud', 'uud', 'uud', 'uud']\n",
      "['uuu', 'udd', 'ddd', 'udd', 'ddu', 'ddd', 'ddu', 'udd', 'udd', 'ddd']\n",
      "['uuu', 'uuu', 'ddd', 'ddd']\n",
      "['uuu', 'uuu', 'ddd', 'fff', 'ddu']\n",
      "['ddd', 'udd', 'udd', 'uud', 'ddd', 'uud', 'udd']\n",
      "['ddd', 'ddd', 'ddd']\n",
      "['duu', 'duu', 'duu', 'uuu', 'duu']\n",
      "['uuu', 'uuu', 'uuu', 'uuu']\n",
      "['duu', 'uuu', 'fff', 'uud', 'ddd', 'uuu', 'uud', 'uud', 'uuu', 'uud', 'uud', 'uud', 'uud', 'duu', 'uud']\n",
      "['duu', 'fff', 'ddd', 'ddd', 'udd', 'ddu', 'udd', 'ddd', 'udd', 'ddd', 'udd', 'ddd', 'ddd']\n",
      "['udd', 'uuu', 'uuu', 'uuu']\n",
      "['duu', 'uuu']\n",
      "['duu', 'uuu', 'uuu', 'uuu', 'uuu', 'uud', 'uuu', 'ddu', 'udd', 'ddu', 'duu', 'uuu', 'uud', 'uuu', 'uud', 'uuu', 'uuu', 'uuu', 'uud', 'uud', 'duu', 'udd', 'uuu', 'duu', 'uud', 'uuu', 'duu', 'uud', 'uud', 'uud', 'uud', 'uud']\n",
      "['uuu', 'udd', 'ddd', 'udd', 'ddu', 'fff', 'uuu', 'duu', 'duu', 'uud', 'udd', 'ddu']\n",
      "['uuu', 'uuu', 'duu', 'udd', 'uuu']\n",
      "['duu', 'uuu', 'uuu', 'uuu']\n",
      "['duu', 'udd', 'ddu', 'udd', 'duu', 'uuu', 'udd']\n",
      "['duu', 'duu', 'uuu']\n",
      "['uud', 'udd', 'uuu', 'duu', 'ddd', 'uuu']\n",
      "['duu', 'duu', 'duu', 'uuu']\n",
      "['uuu', 'duu', 'duu', 'ddd', 'uud']\n",
      "['duu', 'duu', 'uuu']\n",
      "['duu', 'uuu', 'fff', 'uud', 'ddd', 'uuu', 'uud', 'uud', 'uuu', 'uud', 'uud', 'uud', 'uud', 'duu', 'uud']\n",
      "['uuu', 'ddd', 'ddu', 'ddd', 'udd', 'uuu', 'udd', 'uud', 'udd', 'udd']\n",
      "['uud', 'udd', 'uuu', 'duu', 'ddd', 'uuu']\n",
      "['duu', 'uuu', 'uuu', 'uuu']\n",
      "['uud', 'uud', 'ddu', 'duu', 'uud', 'ddu', 'uud', 'uuu', 'fff', 'uud']\n",
      "['ddd', 'uuu', 'ddd', 'uuu', 'fff', 'duu', 'ddd', 'ddd', 'duu', 'udd', 'udd']\n",
      "['ddu', 'ddd', 'uud', 'uud', 'uuu', 'ddu', 'ddu']\n",
      "['fff', 'fff', 'uuu', 'ddd', 'udd', 'udd', 'ddd', 'udd', 'ddd', 'uud']\n",
      "['ddd', 'fff', 'uuu', 'uuu', 'uud', 'fff', 'ddd', 'fff', 'ddu', 'duu', 'ddd', 'ddu']\n",
      "['uuu', 'ddd', 'duu', 'uud', 'udd', 'ddu', 'udd', 'ddd', 'uuu']\n",
      "['ddu', 'ddd', 'uud', 'fff', 'ddd', 'uud', 'udd', 'uuu', 'ddu', 'ddd', 'duu', 'fff', 'fff', 'ddu', 'ddd', 'uud']\n",
      "['uud', 'uud', 'uud', 'fff', 'ddd', 'udd', 'uud', 'ddd', 'duu']\n",
      "['uuu', 'uuu', 'uud', 'uud', 'udd', 'udd', 'ddd', 'uuu']\n",
      "['uuu', 'ddd', 'fff', 'ddu', 'ddu', 'ddd', 'ddu', 'ddd', 'udd', 'ddd', 'uuu', 'udd']\n",
      "['ddd', 'fff', 'fff', 'fff', 'ddu', 'fff', 'uuu', 'uud', 'fff', 'uuu', 'udd']\n",
      "['fff', 'ddd', 'fff', 'udd', 'duu', 'udd', 'udd', 'ddd', 'uud', 'ddd', 'udd']\n",
      "['fff', 'uuu', 'udd', 'udd', 'duu', 'ddu', 'ddu', 'ddd', 'ddu']\n",
      "['uuu', 'duu', 'fff', 'uuu', 'ddd', 'uuu', 'uud', 'ddu', 'udd']\n",
      "['fff', 'ddu', 'fff', 'fff', 'uud', 'duu', 'fff', 'ddu']\n",
      "['uuu', 'uud', 'ddu', 'udd', 'ddu', 'ddu', 'fff', 'udd', 'udd', 'fff', 'ddd', 'udd']\n",
      "['fff', 'uud', 'uuu', 'ddu', 'fff', 'ddd', 'ddu', 'ddu', 'udd', 'ddd', 'udd']\n",
      "['uuu', 'uuu', 'uuu', 'ddd', 'ddd', 'fff', 'uud', 'fff', 'uud', 'uud', 'ddd', 'fff']\n",
      "['fff', 'udd', 'fff', 'udd', 'fff', 'ddd', 'udd', 'fff', 'ddd', 'ddu']\n",
      "['uuu', 'udd', 'fff', 'ddd', 'fff', 'ddd', 'udd', 'udd', 'ddd', 'udd']\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(n_species * 10):\n",
    "    print(states_sti_list[i])\n",
    "    print(states_im_matrix[0,i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
